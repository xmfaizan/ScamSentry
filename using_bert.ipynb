{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14666f57-d898-4e50-8ff5-2b24f3babd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a720d2-5a2f-46cc-80c1-68c42d2dfae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_data(data_file):\n",
    "    df = pd.read_csv(data_file,encoding='utf-8')\n",
    "    texts = df['texts'].tolist()\n",
    "    labels = df['labels'].tolist()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1437844b-5a81-4b15-ba2b-1ab744a0d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'cleaned.csv'\n",
    "texts, labels = review_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181866b0-4873-4670-a537-000454db52df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts: 40432, Total labels: 40432\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total texts: {len(texts)}, Total labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d11424e-c64a-4cc4-a142-617a4c703aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing, handling the seq_length, and providing with input IDs, attention masks, and labels\n",
    "class TextClassificationDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "  def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping example at index {idx}: {e}\")\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038e2c97-7f7b-4573-a3b1-3ffef699b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d27dc41-ee0e-4d2c-b6cc-c61d565c162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)  # Correct key is 'labels'\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0e9de0-d530-4337-8385-1be91c72a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)  # Correct key is 'labels'\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6cfa5f5-5e0c-4509-8aaa-0d6ae3888c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Filter out None items\n",
    "    batch = [item for item in batch if item is not None]\n",
    "\n",
    "    if not batch:  # Handle the case where all items in the batch are None\n",
    "        return None\n",
    "\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_mask = [item['attention_mask'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Convert labels to a tensor\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee79da46-24d6-4a66-999a-2878a9050248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    return \"Authentic Review\" if preds.item() == 1 else \"Computer Generated Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2300e1b2-1974-4468-a736-a4a0a901b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb20a9c9-4882-42f9-9813-95f7726087f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, rem_texts, train_labels, rem_labels = train_test_split(texts, labels, train_size=0.6, random_state=42)\n",
    "\n",
    "# Then split the remaining data into 50% validation and 50% test (which is 20% of total each)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(rem_texts, rem_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7ed12e-0aad-4045-99e8-3e3edc8208c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24259\n",
      "24259\n",
      "8086\n",
      "8086\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(train_labels))\n",
    "print(len(val_texts))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "825f3641-b8c7-4e4b-870d-1e245506229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a8e77e-2bc3-4437-8c0c-fc82d01f2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"true\" if torch.cuda.is_available() else \"false\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed036512-643a-4e82-bc50-73c1eb560694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faiza\\anaconda3\\envs\\nlpbasics\\Lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f024e80-365a-4f1c-a621-b9c4e481c9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faiza\\anaconda3\\envs\\nlpbasics\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      4030\n",
      "           1       0.99      0.89      0.94      4056\n",
      "\n",
      "    accuracy                           0.94      8086\n",
      "   macro avg       0.95      0.94      0.94      8086\n",
      "weighted avg       0.95      0.94      0.94      8086\n",
      "\n",
      "Epoch 2/4\n",
      "Validation Accuracy: 0.9686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4030\n",
      "           1       0.99      0.95      0.97      4056\n",
      "\n",
      "    accuracy                           0.97      8086\n",
      "   macro avg       0.97      0.97      0.97      8086\n",
      "weighted avg       0.97      0.97      0.97      8086\n",
      "\n",
      "Epoch 3/4\n",
      "Validation Accuracy: 0.9531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      4030\n",
      "           1       0.99      0.91      0.95      4056\n",
      "\n",
      "    accuracy                           0.95      8086\n",
      "   macro avg       0.96      0.95      0.95      8086\n",
      "weighted avg       0.96      0.95      0.95      8086\n",
      "\n",
      "Epoch 4/4\n",
      "Validation Accuracy: 0.9580\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4030\n",
      "           1       0.99      0.92      0.96      4056\n",
      "\n",
      "    accuracy                           0.96      8086\n",
      "   macro avg       0.96      0.96      0.96      8086\n",
      "weighted avg       0.96      0.96      0.96      8086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5d63d2-fbf6-47c4-8798-f14d8095d92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4120\n",
      "           1       0.99      0.93      0.96      3967\n",
      "\n",
      "    accuracy                           0.96      8087\n",
      "   macro avg       0.96      0.96      0.96      8087\n",
      "weighted avg       0.96      0.96      0.96      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_accuracy, test_report = evaluate(model, test_dataloader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ca067b5-79a0-4d88-a55d-1e83893e3992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recently bought this smartwatch, and it's been a game-changer for my daily routine. The fitness tracking features are accurate and comprehensive, covering everything from steps to heart rate monitoring. The battery life is impressive, lasting several days on a single charge. Plus, the sleek design makes it a stylish accessory for any outfit. Highly recommend!\n",
      "Predicted sentiment: Authentic Review\n"
     ]
    }
   ],
   "source": [
    "test_text = \"I recently bought this smartwatch, and it's been a game-changer for my daily routine. The fitness tracking features are accurate and comprehensive, covering everything from steps to heart rate monitoring. The battery life is impressive, lasting several days on a single charge. Plus, the sleek design makes it a stylish accessory for any outfit. Highly recommend!\"\n",
    "predict = prediction(test_text, model, tokenizer, device)\n",
    "print(test_text)\n",
    "print(f\"Predicted sentiment: {predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e88e3e0d-dcdb-4174-9e7b-b1e701ed36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "torch.save(model.state_dict(), 'bert_classifier_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7ac29-1392-48e1-bf8a-e16f15861af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
